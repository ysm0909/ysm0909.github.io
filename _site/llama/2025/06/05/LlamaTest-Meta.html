<!DOCTYPE html>
<html lang="en">

<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<link href="https://fonts.googleapis.com/css?family=Merriweather:300|Raleway:400,700" rel="stylesheet">
<link rel="stylesheet" href="/assets/css/style.css">
<title>Llama Test 1(Meta)</title>
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Llama Test 1(Meta) | Your awesome title</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Llama Test 1(Meta)" />
<meta name="author" content="GitHub User" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="reference: Meta llama3.1 직접 다운로드 하기" />
<meta property="og:description" content="reference: Meta llama3.1 직접 다운로드 하기" />
<link rel="canonical" href="http://localhost:4000/llama/2025/06/05/LlamaTest-Meta.html" />
<meta property="og:url" content="http://localhost:4000/llama/2025/06/05/LlamaTest-Meta.html" />
<meta property="og:site_name" content="Your awesome title" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-06-05T17:41:36+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Llama Test 1(Meta)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"GitHub User"},"dateModified":"2025-06-05T17:41:36+09:00","datePublished":"2025-06-05T17:41:36+09:00","description":"reference: Meta llama3.1 직접 다운로드 하기","headline":"Llama Test 1(Meta)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/llama/2025/06/05/LlamaTest-Meta.html"},"url":"http://localhost:4000/llama/2025/06/05/LlamaTest-Meta.html"}</script>
<!-- End Jekyll SEO tag -->


<script type="text/javascript" src="/assets/js/darkmode.js"></script>

</head><body>
  <main class="container">
    <section class="about">
      <div class="about-header condensed">
      <div class="about-title">
      <a href="/">
        
        <img src="/assets/du.jpg" alt="Seungmi Yu" />
        
      </a>
      <h2 id="title">
        <a href="/">Seungmi Yu</a>
      </h2>
      </div><p class="tagline">Student</p></div>
      
      <ul class="social about-footer condensed"><a href="https://github.com/ysm0909" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="mailto:ysmm0909@naver.com" target="_blank">
          <li>
            <i class="icon-mail-alt"></i>
          </li>
        </a></ul><p class="about-footer condensed">&copy;
        2025</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </section>
    <section class="content">
      <div class="post-container">
  <a class="post-link" href="/llama/2025/06/05/LlamaTest-Meta.html">
    <h2 class="post-title">Llama Test 1(Meta)</h2>
  </a>
  <div class="post-meta">
    <div class="post-date"><i class="icon-calendar"></i>Jun 5, 2025</div><ul class="post-categories"><li>Llama</li></ul></div>
  <div class="post">
    <p>reference: <a href="https://pagichacha.tistory.com/328">Meta llama3.1 직접 다운로드 하기</a></p>

<ol>
  <li>
    <p><strong>Meta 사이트 접속</strong></p>

    <p><a href="https://www.llama.com/llama-downloads/">Download Llama</a></p>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image.png" alt="image.png" /></p>

    <p>https://llama3-1.llamameta.net/*?Policy= ~ 생략</p>
  </li>
  <li>
    <p><strong>메일 확인 → 사이트 접속</strong></p>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image%201.png" alt="image.png" /></p>
  </li>
  <li>
    <p><strong>터미널 접속</strong></p>

    <p><strong>Download</strong></p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">pip</span> <span class="n">install</span> <span class="n">llama</span><span class="o">-</span><span class="n">stack</span>
</code></pre></div>    </div>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image%202.png" alt="image.png" /></p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">llama</span> <span class="n">model</span> <span class="nb">list</span>
</code></pre></div>    </div>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image%203.png" alt="image.png" /></p>

    <p>모델 선택: Llama3.1-8B</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">lama</span> <span class="n">download</span> <span class="o">--</span><span class="n">source</span> <span class="n">meta</span> <span class="o">--</span><span class="n">model</span><span class="o">-</span><span class="nb">id</span> <span class="n">Llama3</span><span class="p">.</span><span class="mi">1</span><span class="o">-</span><span class="mi">8</span><span class="n">B</span>
</code></pre></div>    </div>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image%204.png" alt="image.png" /></p>

    <p>받은 url 입력</p>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image%205.png" alt="image.png" /></p>

    <p><strong>Delete</strong></p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">find</span> <span class="o">~</span> <span class="o">-</span><span class="nb">type</span> <span class="n">d</span> <span class="o">-</span><span class="n">name</span> <span class="sh">"</span><span class="s">Llama3</span><span class="sh">"</span>
</code></pre></div>    </div>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image%206.png" alt="image.png" /></p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">rm</span> <span class="o">-</span><span class="n">rf</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">seoin</span><span class="o">/</span><span class="p">.</span><span class="n">llama</span><span class="o">/</span><span class="n">checkpoints</span><span class="o">/</span><span class="n">Llama3</span><span class="p">.</span><span class="mi">1</span><span class="o">-</span><span class="mi">8</span><span class="n">B</span>
</code></pre></div>    </div>

    <p><strong>Way2 (llama3 설치)</strong></p>

    <p><a href="https://www.youtube.com/watch?v=lJwkv3J6o54">라마(LLama3.*) - Meta 웹사이트에서 직접 다운로드 및 리눅스 서버에서 운영</a></p>

    <ol>
      <li><strong>터미널 접속</strong></li>
    </ol>

    <p>실습 디렉토리: cd /home/seoin/Documents/llama_test</p>

    <p><strong>Download</strong></p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">wget</span>
 <span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">md5sum</span>
</code></pre></div>    </div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">git</span> <span class="n">clone</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="p">.</span><span class="n">com</span><span class="o">/</span><span class="n">meta</span><span class="o">-</span><span class="n">llama</span><span class="o">/</span><span class="n">llama3</span><span class="p">.</span><span class="n">git</span>
    
 <span class="n">cd</span> <span class="n">llama3</span>
    
 <span class="n">ls</span>
</code></pre></div>    </div>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image%207.png" alt="image.png" /></p>

    <p><a href="http://setup.py">setup.py</a> 활용해 필요한 패키지 종속성 설치</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">e</span> <span class="p">.</span>
</code></pre></div>    </div>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="p">.</span><span class="o">/</span><span class="n">download</span><span class="p">.</span><span class="n">sh</span>
</code></pre></div>    </div>

    <p>Enter the URL from email: 받은 url 입력</p>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image%208.png" alt="image.png" /></p>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image%209.png" alt="image.png" /></p>

    <p>필요한 모델 다운로드: 8B,8B-instruct</p>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image%2010.png" alt="image.png" /></p>

    <p>다운로드 확인</p>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image%2011.png" alt="image.png" /></p>

    <p><strong>Test</strong></p>

    <ol>
      <li><strong>example_text_completion.py</strong></li>
    </ol>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">def</span> <span class="nf">main</span><span class="p">(</span>
     <span class="n">ckpt_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>              <span class="c1"># 모델 체크포인트 디렉토리 경로
</span>     <span class="n">tokenizer_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>        <span class="c1"># 토크나이저 파일 또는 디렉토리 경로
</span>     <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>   <span class="c1"># 생성 다양성 조절 (낮을수록 더 결정적인 출력) 낮을수록 덜 무작위
</span>     <span class="n">top_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>         <span class="c1"># 상위 p 누적 확률의 토큰에서 샘플링 (nucleus sampling)
</span>     <span class="n">max_seq_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>     <span class="c1"># 입력 시퀀스의 최대 길이
</span>     <span class="n">max_gen_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>      <span class="c1"># 생성할 최대 토큰 수
</span>     <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>    <span class="c1"># 한 번에 처리할 최대 입력 개수
</span> <span class="p">):</span>
</code></pre></div>    </div>

    <p>example_text_completion.py 실행</p>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image%2012.png" alt="image.png" /></p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span> <span class="mi">1</span> <span class="n">example_text_completion</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">ckpt_dir</span> <span class="n">Meta</span><span class="o">-</span><span class="n">Llama</span><span class="o">-</span><span class="mi">3</span><span class="o">-</span><span class="mi">8</span><span class="n">B</span><span class="o">/</span> <span class="o">--</span><span class="n">tokenizer_path</span> <span class="n">Meta</span><span class="o">-</span><span class="n">Llama</span><span class="o">-</span><span class="mi">3</span><span class="o">-</span><span class="mi">8</span><span class="n">B</span><span class="o">/</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">model</span> <span class="o">--</span><span class="n">max_seq_len</span> <span class="mi">128</span> <span class="o">--</span><span class="n">max_batch_size</span> <span class="mi">4</span> 
</code></pre></div>    </div>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">torchrun</code>은 분산 학습이나 멀티 GPU 환경에서 PyTorch 스크립트를 실행할 때 사용</li>
      <li><code class="language-plaintext highlighter-rouge">-nproc-per-node=1</code>이면 <strong>GPU 한 개만 사용</strong></li>
    </ul>

    <p>실행 결과</p>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image%2013.png" alt="image.png" /></p>

    <p>밑줄: 프롬프트, &gt; : 답변</p>

    <ol>
      <li><strong>example_chat_completion.py</strong></li>
    </ol>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">def</span> <span class="nf">main</span><span class="p">(</span>
     <span class="n">ckpt_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>              <span class="c1"># 모델 체크포인트가 저장된 디렉토리 경로
</span>     <span class="n">tokenizer_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>        <span class="c1"># 토크나이저 파일 또는 디렉토리 경로
</span>     <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>   <span class="c1"># 생성 텍스트의 다양성을 조절 (낮을수록 보수적)
</span>     <span class="n">top_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>         <span class="c1"># 누적 확률 p 이하의 토큰들 중에서 샘플링 (nucleus sampling)
</span>     <span class="n">max_seq_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>     <span class="c1"># 입력 시퀀스의 최대 길이
</span>     <span class="n">max_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>    <span class="c1"># 한 번에 처리할 최대 배치 크기
</span>     <span class="n">max_gen_len</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>  <span class="c1"># 생성할 최대 토큰 수 (None이면 자동 결정)
</span> <span class="p">):</span>
</code></pre></div>    </div>

    <p>대화 예제</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">dialogs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dialog</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span>
         <span class="p">[{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">what is the recipe of mayonnaise?</span><span class="sh">"</span><span class="p">}],</span>
         <span class="p">[</span>
             <span class="p">{</span><span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">user</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">I am going to Paris, what should I see?</span><span class="sh">"</span><span class="p">},</span>
             <span class="p">{</span>
                 <span class="sh">"</span><span class="s">role</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">assistant</span><span class="sh">"</span><span class="p">,</span>
                 <span class="sh">"</span><span class="s">content</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"""</span><span class="se">\
</span></code></pre></div>    </div>

    <p>답변 생성해서 출력하는 부분</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">results</span> <span class="o">=</span> <span class="n">generator</span><span class="p">.</span><span class="n">chat_completion</span><span class="p">(</span>
         <span class="n">dialogs</span><span class="p">,</span>
         <span class="n">max_gen_len</span><span class="o">=</span><span class="n">max_gen_len</span><span class="p">,</span>
         <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
         <span class="n">top_p</span><span class="o">=</span><span class="n">top_p</span><span class="p">,</span>
</code></pre></div>    </div>

    <p>example_chat_completion.py 실행</p>

    <p><img src="/assets/image/2025-06-05-LlamaTest-Meta-Image/image%2014.png" alt="image.png" /></p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">torchrun</span> <span class="o">--</span><span class="n">nproc_per_node</span> <span class="mi">1</span> <span class="n">example_chat_completion</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">ckpt_dir</span> <span class="n">Meta</span><span class="o">-</span><span class="n">Llama</span><span class="o">-</span><span class="mi">3</span><span class="o">-</span><span class="mi">8</span><span class="n">B</span><span class="o">/</span> <span class="o">--</span><span class="n">tokenizer_path</span> <span class="n">Meta</span><span class="o">-</span><span class="n">Llama</span><span class="o">-</span><span class="mi">3</span><span class="o">-</span><span class="mi">8</span><span class="n">B</span><span class="o">/</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">model</span> <span class="o">--</span><span class="n">max_seq_len</span> <span class="mi">512</span> <span class="o">--</span><span class="n">max_batch_size</span> <span class="mi">6</span> 
</code></pre></div>    </div>
  </li>
</ol>


  </div></div>

    </section>
    <footer class="condensed">
      <ul class="social about-footer condensed"><a href="https://github.com/ysm0909" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="mailto:ysmm0909@naver.com" target="_blank">
          <li>
            <i class="icon-mail-alt"></i>
          </li>
        </a></ul><p class="about-footer condensed">&copy;
        2025</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </footer>
  </main>
  
  <script type="text/javascript" src="/assets/js/darkmode.js"></script>
  
  <script src="/assets/js/simple-jekyll-search.min.js"></script>
  <script src="/assets/js/search.js"></script>
  
</body>

</html>
