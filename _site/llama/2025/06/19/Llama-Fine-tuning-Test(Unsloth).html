<!DOCTYPE html>
<html lang="en">

<head><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<link href="https://fonts.googleapis.com/css?family=Merriweather:300|Raleway:400,700" rel="stylesheet">
<link rel="stylesheet" href="/assets/css/style.css">
<title>Llama Fine-tuning Test(Unsloth)</title>
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Llama Fine-tuning Test(Unsloth) | Your awesome title</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Llama Fine-tuning Test(Unsloth)" />
<meta name="author" content="GitHub User" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="reference: Unsloth" />
<meta property="og:description" content="reference: Unsloth" />
<link rel="canonical" href="http://localhost:4000/llama/2025/06/19/Llama-Fine-tuning-Test(Unsloth).html" />
<meta property="og:url" content="http://localhost:4000/llama/2025/06/19/Llama-Fine-tuning-Test(Unsloth).html" />
<meta property="og:site_name" content="Your awesome title" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-06-19T13:13:36+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Llama Fine-tuning Test(Unsloth)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"GitHub User"},"dateModified":"2025-06-19T13:13:36+09:00","datePublished":"2025-06-19T13:13:36+09:00","description":"reference: Unsloth","headline":"Llama Fine-tuning Test(Unsloth)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/llama/2025/06/19/Llama-Fine-tuning-Test(Unsloth).html"},"url":"http://localhost:4000/llama/2025/06/19/Llama-Fine-tuning-Test(Unsloth).html"}</script>
<!-- End Jekyll SEO tag -->


<script type="text/javascript" src="/assets/js/darkmode.js"></script>

</head><body>
  <main class="container">
    <section class="about">
      <div class="about-header condensed">
      <div class="about-title">
      <a href="/">
        
        <img src="/assets/du.jpg" alt="Seungmi Yu" />
        
      </a>
      <h2 id="title">
        <a href="/">Seungmi Yu</a>
      </h2>
      </div><p class="tagline">Student</p></div>
      
      <ul class="social about-footer condensed"><a href="https://github.com/ysm0909" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="mailto:ysmm0909@naver.com" target="_blank">
          <li>
            <i class="icon-mail-alt"></i>
          </li>
        </a></ul><p class="about-footer condensed">&copy;
        2025</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </section>
    <section class="content">
      <div class="post-container">
  <a class="post-link" href="/llama/2025/06/19/Llama-Fine-tuning-Test(Unsloth).html">
    <h2 class="post-title">Llama Fine-tuning Test(Unsloth)</h2>
  </a>
  <div class="post-meta">
    <div class="post-date"><i class="icon-calendar"></i>Jun 19, 2025</div><ul class="post-categories"><li>Llama</li></ul></div>
  <div class="post">
    <p>reference: <a href="https://github.com/unslothai/unsloth">Unsloth</a></p>

<h1 id="ï¸-setting"><strong>âš™ï¸</strong> Setting</h1>

<h2 id="-1-ê°€ìƒí™˜ê²½-ìƒì„±">âœ… 1. ê°€ìƒí™˜ê²½ ìƒì„±<strong>â—</strong></h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#step1</span>
conda create <span class="nt">-n</span> unsloth_env <span class="nv">python</span><span class="o">=</span>3.11 <span class="nt">-y</span>

<span class="c">#step2</span>
conda activate unsloth_env

<span class="c">#step3</span>
<span class="c"># PyTorch + CUDA 12.1 (pipë¡œ ì„¤ì¹˜, ê³µì‹ wheel)</span>
pip <span class="nb">install </span>torch torchvision torchaudio <span class="nt">--index-url</span> https://download.pytorch.org/whl/cu121
</code></pre></div></div>

<h2 id="-2-cuda-ì„¤ì¹˜-ì—¬ë¶€-í™•ì¸">âœ… 2. CUDA ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nvcc <span class="nt">--version</span>
</code></pre></div></div>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image.png" alt="image.png" /></p>

<h2 id="-3-pytorchê°€-gpuë¥¼-ì‚¬ìš©í•˜ëŠ”ì§€-í™•ì¸">âœ… 3. PyTorchê°€ GPUë¥¼ ì‚¬ìš©í•˜ëŠ”ì§€ í™•ì¸</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€: </span><span class="sh">"</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">())</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">GPU: </span><span class="sh">"</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">"</span><span class="s">ì‚¬ìš©ë¶ˆê°€</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image%201.png" alt="image.png" /></p>

<h2 id="-4-pytorch-gpu-ë²„ì „-ì„¤ì¹˜-í™•ì¸">âœ… 4. PyTorch GPU ë²„ì „ ì„¤ì¹˜ í™•ì¸</h2>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image%202.png" alt="image.png" /></p>

<p>âš ï¸ í˜¸í™˜ ë²„ì „ í™•ì¸ â¬‡ï¸</p>

<p>For other torch versions, we supportÂ <code class="language-plaintext highlighter-rouge">torch211</code>,Â <code class="language-plaintext highlighter-rouge">torch212</code>,Â <code class="language-plaintext highlighter-rouge">torch220</code>,Â <code class="language-plaintext highlighter-rouge">torch230</code>,Â <code class="language-plaintext highlighter-rouge">torch240</code>Â and for CUDA versions, we supportÂ <code class="language-plaintext highlighter-rouge">cu118</code>Â andÂ <code class="language-plaintext highlighter-rouge">cu121</code>Â andÂ <code class="language-plaintext highlighter-rouge">cu124</code>.Â </p>

<h2 id="ï¸-vs-code-ê²½ê³ -í•´ê²°">âš ï¸ VS Code ê²½ê³  í•´ê²°</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>We noticed you're using a conda environment. If you are experiencing issues with this environment in the integrated terminal, we recommend that you let the Python extension change "terminal.integrated.inheritEnv" to false in your user settings
</code></pre></div></div>

<p>â¡ï¸ VS Codeì—ì„œ ì—´ë ¤ ìˆëŠ” í„°ë¯¸ë„ì´ <strong>conda ê°€ìƒí™˜ê²½ì„ ì œëŒ€ë¡œ ì¸ì‹í•˜ì§€ ëª»í•  ìˆ˜ë„ ìˆë‹¤</strong>ëŠ” ì˜ë¯¸</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">Ctrl + Shift + P</code> â†’ <code class="language-plaintext highlighter-rouge">Preferences: Open User Settings (JSON)</code></li>
</ul>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image%203.png" alt="image.png" /></p>

<h1 id="1ï¸âƒ£-installation">1ï¸âƒ£ Installation</h1>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>unsloth
</code></pre></div></div>

<p>â•python í™˜ê²½: 3.10 ì´ìƒ</p>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image%204.png" alt="image.png" /></p>

<p>â¡ï¸ torchaudio ì‚¬ìš©í•  ì¼ ì—†ì„ ê±° ê°™ìœ¼ë‹ˆ ì¼ë‹¨ ë³´ë¥˜</p>

<h1 id="2ï¸âƒ£-unsloth">2ï¸âƒ£ <strong>Unsloth</strong></h1>

<h2 id="ï¸-unslothmeta-llama-31-8b-instruct-bnb-4bit--ì‚¬ìš©">â¡ï¸ <code class="language-plaintext highlighter-rouge">unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit</code>  ì‚¬ìš©!</h2>

<p>from datasets import load_dataset
dataset = load_dataset(â€œhpe-ai/medical-cases-classification-tutorialâ€, split=â€trainâ€)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># âœ… Unslothì—ì„œ ì œê³µí•˜ëŠ” ë¹ ë¥¸ LLM ë¡œë”© ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ import
</span><span class="kn">from</span> <span class="n">unsloth</span> <span class="kn">import</span> <span class="n">FastLanguageModel</span>

<span class="c1"># âœ… PyTorchëŠ” í…ì„œ ê³„ì‚°, GPU ì—°ì‚° ë“±ì„ ìœ„í•œ í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
</span><span class="kn">import</span> <span class="n">torch</span>

<span class="c1"># âœ… ìµœëŒ€ í† í° ê¸¸ì´ ì„¤ì • (ì˜ˆ: í•˜ë‚˜ì˜ ë¬¸ì¥ì´ 2048 í† í°ê¹Œì§€ ê°€ëŠ¥)
</span><span class="n">max_seq_length</span> <span class="o">=</span> <span class="mi">2048</span>  <span class="c1"># ì›í•˜ëŠ” ê¸¸ì´ë¡œ ì„¤ì • ê°€ëŠ¥! ë‚´ë¶€ì ìœ¼ë¡œ RoPE Scaling ì§€ì›ë¨
</span>
<span class="c1"># âœ… ë°ì´í„° íƒ€ì… ì„¤ì •
# - Noneìœ¼ë¡œ ë‘ë©´ ìë™ ê°ì§€ë¨
# - float16ì€ T4, V100 GPUì— ì í•©
# - bfloat16ì€ A100, RTX 3090, 4090 ë“± Ampere ì´ìƒì— ì í•©
</span><span class="n">dtype</span> <span class="o">=</span> <span class="bp">None</span>

<span class="c1"># âœ… 4bit ì–‘ìí™” ì‚¬ìš© ì—¬ë¶€
# - Trueë¡œ í•˜ë©´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì¤„ê³  í•™ìŠµ ë° ì¶”ë¡ ì´ ë” ë¹¨ë¼ì§
</span><span class="n">load_in_4bit</span> <span class="o">=</span> <span class="bp">True</span>

<span class="c1"># âœ… ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë”©
</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
</span>    <span class="n">max_seq_length</span> <span class="o">=</span> <span class="n">max_seq_length</span><span class="p">,</span>          <span class="c1"># ìµœëŒ€ ì…ë ¥ ê¸¸ì´
</span>    <span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span><span class="p">,</span>                            <span class="c1"># float16, bfloat16, None ì¤‘ ì„ íƒ
</span>    <span class="n">load_in_4bit</span> <span class="o">=</span> <span class="n">load_in_4bit</span><span class="p">,</span>              <span class="c1"># 4bit ì–‘ìí™” ì‚¬ìš© ì—¬ë¶€(ì–‘ìí™” ëª¨ë¸: ë‹¤ì‹œ ì–‘ìí™”í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼, ì˜¬ë°”ë¥´ê²Œ ë¡œë”©í•˜ëŠ” ìš©ë„)
</span>    <span class="n">token</span> <span class="o">=</span> <span class="sh">"</span><span class="s">hf_...</span><span class="sh">"</span>                        <span class="c1"># í—ˆê¹…í˜ì´ìŠ¤ì˜ ì ‘ê·¼ í† í° (Gated ëª¨ë¸ì¸ ê²½ìš° í•„ìš”)
</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image%205.png" alt="image.png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># âœ… ë¯¸ë¦¬ 4bitë¡œ ì–‘ìí™”ëœ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸
# - ë‹¤ìš´ë¡œë“œ ì†ë„ê°€ ë¹ ë¥´ê³  ë©”ëª¨ë¦¬ ë¶€ì¡±(OOM) ë¬¸ì œë„ ì¤„ì–´ë“¦
fourbit_models = [
    "unsloth/Meta-Llama-3.1-8B-bnb-4bit",      # Llama 3.1 - 8B ëª¨ë¸, 2ë°° ë¹ ë¥¸ ì„±ëŠ¥
    "unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit",
    "unsloth/Meta-Llama-3.1-70B-bnb-4bit",
    "unsloth/Meta-Llama-3.1-405B-bnb-4bit",    # 405B ëª¨ë¸ë„ 4bitë¡œ ì§€ì›!
    "unsloth/Mistral-Nemo-Base-2407-bnb-4bit", # ìƒˆ ë²„ì „ Mistral 12B ëª¨ë¸, ì„±ëŠ¥ í–¥ìƒ
    "unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit",
    "unsloth/mistral-7b-v0.3-bnb-4bit",        # Mistral v0.3 ë²„ì „
    "unsloth/mistral-7b-instruct-v0.3-bnb-4bit",
    "unsloth/Phi-3.5-mini-instruct",           # Phi 3.5 ëª¨ë¸
    "unsloth/Phi-3-medium-4k-instruct",
    "unsloth/gemma-2-9b-bnb-4bit",
    "unsloth/gemma-2-27b-bnb-4bit",            # Google Gemma ëª¨ë¸ë„ ì§€ì›ë¨
]  # ì „ì²´ ëª¨ë¸ ëª©ë¡ì€ https://huggingface.co/unsloth ì°¸ê³ 
</code></pre></div></div>

<h3 id="-fastlanguagemodelfrom_pretrained">ğŸ“ <code class="language-plaintext highlighter-rouge">FastLanguageModel.from_pretrained</code></h3>

<ul>
  <li>Hugging Faceì— ìˆëŠ” ëª¨ë¸ì„ <strong>ë¹ ë¥´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•œ í•¨ìˆ˜</strong></li>
  <li>Unslothê°€ ë‚´ë¶€ì ìœ¼ë¡œ 4bit ì§€ì›, í† í¬ë‚˜ì´ì € ìµœì í™”, GPU ìµœì í™” ë“± ì²˜ë¦¬</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># LoRA adapters 
</span><span class="n">model</span> <span class="o">=</span> <span class="n">FastLanguageModel</span><span class="p">.</span><span class="nf">get_peft_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    
    <span class="c1"># LoRAì˜ rank ê°’. í´ìˆ˜ë¡ í‘œí˜„ë ¥ì€ ì˜¬ë¼ê°€ì§€ë§Œ VRAM ì‚¬ìš©ëŸ‰ë„ ì¦ê°€í•©ë‹ˆë‹¤.
</span>    <span class="n">r</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>  <span class="c1"># 8, 16, 32, 64, 128 ë“± ì‚¬ìš© ê°€ëŠ¥
</span>
    <span class="c1"># LoRAë¥¼ ì ìš©í•  ëŒ€ìƒ ëª¨ë“ˆë“¤. Transformerì˜ í•µì‹¬ ì—°ì‚° ë¶€ë¶„ì…ë‹ˆë‹¤.
</span>    <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">q_proj</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">k_proj</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">v_proj</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">o_proj</span><span class="sh">"</span><span class="p">,</span>
                      <span class="sh">"</span><span class="s">gate_proj</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">up_proj</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">down_proj</span><span class="sh">"</span><span class="p">,],</span>

    <span class="c1"># LoRAì˜ scaling factorë¡œ, ë³´í†µ rê³¼ ê°™ì€ ê°’ì„ ì£¼ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.
</span>    <span class="n">lora_alpha</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>

    <span class="c1"># LoRAì— ì ìš©í•  dropout ë¹„ìœ¨. 0ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì„±ëŠ¥ ë° ì†ë„ ìµœì í™”ì— ìœ ë¦¬í•©ë‹ˆë‹¤.
</span>    <span class="n">lora_dropout</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>  <span class="c1"># ì–´ë–¤ ê°’ì´ë“  ê°€ëŠ¥í•˜ë‚˜, 0ì´ ê°€ì¥ ìµœì í™”ë˜ì–´ ìˆìŒ
</span>
    <span class="c1"># bias í•™ìŠµ ì—¬ë¶€. "none"ì´ë©´ bias íŒŒë¼ë¯¸í„°ëŠ” í•™ìŠµí•˜ì§€ ì•ŠìŒ (ì„±ëŠ¥/ì†ë„ ìµœì í™”ë¨)
</span>    <span class="c1"># bias: ë‰´ëŸ°ì´ ë” ë‹¤ì–‘í•œ ê°’ì„ ì¶œë ¥í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ì¶”ê°€ì ì¸ ìƒìˆ˜
</span>		<span class="c1"># LoRAì—ì„œëŠ” ëŒ€ë¶€ë¶„ í•™ìŠµ ëŒ€ìƒì—ì„œ ì œì™¸ì‹œì¼œë„ ë¬´ë°©
</span>    <span class="n">bias</span> <span class="o">=</span> <span class="sh">"</span><span class="s">none</span><span class="sh">"</span><span class="p">,</span>

    <span class="c1"># âœ… "unsloth"ì˜ ì»¤ìŠ¤í…€ ì²´í¬í¬ì¸íŒ… ë°©ì‹ì€ VRAMì„ 30% ì ˆì•½í•˜ê³ , batch sizeë¥¼ 2ë°° í‚¤ìš¸ ìˆ˜ ìˆìŒ
</span>    <span class="n">use_gradient_checkpointing</span> <span class="o">=</span> <span class="sh">"</span><span class="s">unsloth</span><span class="sh">"</span><span class="p">,</span>  <span class="c1"># True ë˜ëŠ” "unsloth" ì‚¬ìš© ê°€ëŠ¥
</span>
    <span class="c1"># ëœë¤ì„± ê³ ì •ì„ ìœ„í•œ ì‹œë“œê°’ ì„¤ì • (ì¬í˜„ì„± ë³´ì¥)
</span>    <span class="n">random_state</span> <span class="o">=</span> <span class="mi">3407</span><span class="p">,</span>

    <span class="c1"># LoRAì˜ ë³€í˜• ê¸°ë²• ì¤‘ í•˜ë‚˜ì¸ Rank-Stabilized LoRA ì‚¬ìš© ì—¬ë¶€
</span>    <span class="n">use_rslora</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>  <span class="c1"># ì¼ë°˜ì ì¸ LoRA ì‚¬ìš©
</span>
    <span class="c1"># LoftQë¼ëŠ” ë˜ ë‹¤ë¥¸ ì–‘ìí™” í•™ìŠµ ê¸°ë²• ì„¤ì • (ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ Noneìœ¼ë¡œ ì„¤ì •)
</span>    <span class="n">loftq_config</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<h1 id="3ï¸âƒ£-data-prep">3ï¸âƒ£ Data Prep</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Alpaca í˜•ì‹ì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
</span><span class="n">alpaca_prompt</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
{}

### Input:
{}

### Response:
{}</span><span class="sh">"""</span>

<span class="c1"># ëª¨ë¸ì˜ EOS (End of Sequence) í† í°ì„ ê°€ì ¸ì˜´ â€“ í…ìŠ¤íŠ¸ ë í‘œì‹œìš©
</span><span class="n">EOS_TOKEN</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">eos_token</span>  <span class="c1"># ë°˜ë“œì‹œ EOS_TOKENì„ ì¶”ê°€í•´ì•¼ í•¨ (í…ìŠ¤íŠ¸ê°€ ë¬´í•œíˆ ìƒì„±ë˜ì§€ ì•Šë„ë¡ í•¨)
</span>
<span class="c1"># ë°ì´í„°ì…‹ì˜ ê° ì˜ˆì œë¥¼ Alpaca í”„ë¡¬í”„íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
</span><span class="k">def</span> <span class="nf">formatting_prompts_func</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="c1"># ë¶„ë¥˜ ëª¨ë¸ ìƒì„±ìœ„í•´ Instruction ì •ì˜
</span>    <span class="n">instructions</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Classify the following medical transcription into the correct medical specialty.</span><span class="sh">"</span>
    <span class="n">inputs</span>       <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">input</span><span class="sh">"</span><span class="p">]</span>        <span class="c1"># input ì—´ ê°€ì ¸ì˜¤ê¸°
</span>    <span class="n">outputs</span>      <span class="o">=</span> <span class="n">examples</span><span class="p">[</span><span class="sh">"</span><span class="s">output</span><span class="sh">"</span><span class="p">]</span>       <span class="c1"># output ì—´ ê°€ì ¸ì˜¤ê¸°
</span>    
    <span class="c1"># instruction, input, outputì„ í”„ë¡¬í”„íŠ¸ í˜•ì‹ì— ë§ê²Œ ì±„ìš°ê³  EOS í† í° ì¶”ê°€
</span>    <span class="n">texts</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">alpaca_prompt</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">instruction</span><span class="p">,</span> <span class="n">input_</span><span class="p">,</span> <span class="n">output_</span><span class="p">)</span> <span class="o">+</span> <span class="n">EOS_TOKEN</span>
        <span class="k">for</span> <span class="n">input_</span><span class="p">,</span> <span class="n">output_</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="p">{</span><span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">:</span> <span class="n">texts</span><span class="p">}</span> <span class="c1"># HuggingFace datasets í¬ë§·ì— ë§ê²Œ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜
# ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸° (train splitë§Œ ì‚¬ìš©)
</span><span class="kn">from</span> <span class="n">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="sh">"</span><span class="s">hpe-ai/medical-cases-classification-tutorial</span><span class="sh">"</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># map í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ë°ì´í„°ì…‹ ì „ì²´ì— formatting_prompts_func ì ìš©
# batched=True ì„¤ì • ì‹œ í•œ ë²ˆì— ì—¬ëŸ¬ ìƒ˜í”Œì„ ì²˜ë¦¬ ê°€ëŠ¥ (ì„±ëŠ¥ í–¥ìƒ)
</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nf">map</span><span class="p">(</span><span class="n">formatting_prompts_func</span><span class="p">,</span> <span class="n">batched</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

</code></pre></div></div>

<h1 id="4ï¸âƒ£-train-the-model">4ï¸âƒ£ <strong>Train the model</strong></h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">trl</span> <span class="kn">import</span> <span class="n">SFTTrainer</span>
<span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>
<span class="kn">from</span> <span class="n">unsloth</span> <span class="kn">import</span> <span class="n">is_bfloat16_supported</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="nc">SFTTrainer</span><span class="p">(</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">,</span>                          <span class="c1"># íŒŒì¸íŠœë‹í•  ì‚¬ì „í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸
</span>    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">,</span>                  <span class="c1"># ëª¨ë¸ì— ë§ëŠ” í† í¬ë‚˜ì´ì €
</span>    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">,</span>                <span class="c1"># í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹
</span>    <span class="n">dataset_text_field</span> <span class="o">=</span> <span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">,</span>            <span class="c1"># ë°ì´í„°ì…‹ ë‚´ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” í•„ë“œ ì´ë¦„
</span>    <span class="n">max_seq_length</span> <span class="o">=</span> <span class="n">max_seq_length</span><span class="p">,</span>       <span class="c1"># ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ (í† í° ìˆ˜)
</span>    <span class="n">dataset_num_proc</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>                   <span class="c1"># ë°ì´í„° ì „ì²˜ë¦¬ì— ì‚¬ìš©í•  í”„ë¡œì„¸ìŠ¤ ê°œìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬)
</span>    <span class="n">packing</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>                        <span class="c1"># ì§§ì€ ì‹œí€€ìŠ¤ ë¶™ì—¬ì„œ ë°°ì¹˜ ì²˜ë¦¬í•˜ëŠ” ê¸°ëŠ¥ (ì†ë„ í–¥ìƒìš©), ì—¬ê¸°ì„  ë¹„í™œì„±í™”
</span>    <span class="n">args</span> <span class="o">=</span> <span class="nc">TrainingArguments</span><span class="p">(</span>
        <span class="n">per_device_train_batch_size</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span>   <span class="c1"># í•œ GPU ë‹¹ ë°°ì¹˜ í¬ê¸°
</span>        <span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>   <span class="c1"># ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ìŠ¤í… ìˆ˜ (ì‹¤ì§ˆ ë°°ì¹˜ í¬ê¸° = 2 * 4 = 8)
</span>        <span class="n">warmup_steps</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>                  <span class="c1"># í•™ìŠµ ì´ˆê¸° í•™ìŠµë¥  ì ì§„ì  ì¦ê°€ ê¸°ê°„
</span>        <span class="c1"># num_train_epochs = 1,            # ì „ì²´ ì—í¬í¬ ìˆ˜ (ì£¼ì„ ì²˜ë¦¬ë¨, ëŒ€ì‹  max_steps ì‚¬ìš©)
</span>        <span class="n">max_steps</span> <span class="o">=</span> <span class="mi">60</span><span class="p">,</span>                    <span class="c1"># ìµœëŒ€ í•™ìŠµ ìŠ¤í… ìˆ˜ (60 ìŠ¤í…ê¹Œì§€ë§Œ í•™ìŠµ)
</span>        <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">2e-4</span><span class="p">,</span>             <span class="c1"># í•™ìŠµë¥ 
</span>        <span class="n">fp16</span> <span class="o">=</span> <span class="ow">not</span> <span class="nf">is_bfloat16_supported</span><span class="p">(),</span>   <span class="c1"># bf16 ë¯¸ì§€ì› ì‹œ fp16 ì‚¬ìš© (í˜¼í•© ì •ë°€ë„)
</span>        <span class="n">bf16</span> <span class="o">=</span> <span class="nf">is_bfloat16_supported</span><span class="p">(),</span>        <span class="c1"># bf16 ì§€ì› ì‹œ í™œì„±í™”
</span>        <span class="n">logging_steps</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>                <span class="c1"># ëª‡ ìŠ¤í…ë§ˆë‹¤ ë¡œê·¸ ê¸°ë¡í• ì§€ (ì—¬ê¸°ì„  ë§¤ ìŠ¤í…)
</span>        <span class="n">optim</span> <span class="o">=</span> <span class="sh">"</span><span class="s">adamw_8bit</span><span class="sh">"</span><span class="p">,</span>             <span class="c1"># 8ë¹„íŠ¸ ì–‘ìí™”ëœ AdamW ì˜µí‹°ë§ˆì´ì € ì‚¬ìš© (ë©”ëª¨ë¦¬ ì ˆì•½ ëª©ì )
</span>        <span class="n">weight_decay</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>              <span class="c1"># ê°€ì¤‘ì¹˜ ê°ì‡  ê³„ìˆ˜ (ì •ê·œí™”)
</span>        <span class="n">lr_scheduler_type</span> <span class="o">=</span> <span class="sh">"</span><span class="s">linear</span><span class="sh">"</span><span class="p">,</span>     <span class="c1"># í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ (ì„ í˜• ê°ì†Œ)
</span>        <span class="n">seed</span> <span class="o">=</span> <span class="mi">3407</span><span class="p">,</span>                      <span class="c1"># ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •
</span>        <span class="n">output_dir</span> <span class="o">=</span> <span class="sh">"</span><span class="s">outputs</span><span class="sh">"</span><span class="p">,</span>           <span class="c1"># ì²´í¬í¬ì¸íŠ¸ ì €ì¥ í´ë” ê²½ë¡œ
</span>        <span class="n">report_to</span> <span class="o">=</span> <span class="sh">"</span><span class="s">none</span><span class="sh">"</span><span class="p">,</span>               <span class="c1"># WandB ë“± ì™¸ë¶€ ë¡œê·¸ ë¹„í™œì„±í™”
</span>    <span class="p">),</span>
<span class="p">)</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trainer_stats</span> <span class="o">=</span> <span class="n">trainer</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image%206.png" alt="image.png" /></p>

<h1 id="5ï¸âƒ£-inference">5ï¸âƒ£ <strong>Inference</strong></h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># ğŸ§¾ Prompt í˜•ì‹ ë™ì¼í•˜ê²Œ ìœ ì§€
</span><span class="n">alpaca_prompt</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
{}

### Input:
{}

### Response:
{}</span><span class="sh">"""</span>

<span class="c1"># âœ… ì˜ˆì‹œ ë¬¸ì¥ (Inferenceìš©)
</span><span class="n">instruction</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Classify the following medical transcription into the correct medical specialty.</span><span class="sh">"</span>
<span class="n">transcription</span> <span class="o">=</span> <span class="sh">"</span><span class="s">PREOPERATIVE DIAGNOSES:,1. Right axillary adenopathy.,2. Thrombocytopenia.,3. Hepatosplenomegaly.,POSTOPERATIVE DIAGNOSES:,1. Right axillary adenopathy.,2. Thrombocytopenia.,3. Hepatosplenomegaly.,PROCEDURE PERFORMED: ,Right axillary lymph node biopsy.,ANESTHESIA: , Local with sedation.,COMPLICATIONS: , None.,DISPOSITION: , The patient tolerated the procedure well and was transferred to the recovery room in stable condition.,BRIEF HISTORY: ,The patient is a 37-year-old male who presented to ABCD General Hospital secondary to hiccups and was ultimately found to have a right axillary mass to be severely thrombocytopenic with a platelet count of 2000 as well as having hepatosplenomegaly. The working diagnosis is lymphoma, however, the Hematology and Oncology Departments were requesting a lymph node biopsy in order to confirm the diagnosis as well as prognosis. Thus, the patient was scheduled for a lymph node biopsy with platelets running secondary to thrombocytopenia at the time of surgery.,INTRAOPERATIVE FINDINGS: , The patient was found to have a large right axillary lymphadenopathy, one of the lymph node was sent down as a fresh specimen.,PROCEDURE: ,After informed written consent, risks and benefits of this procedure were explained to the patient. The patient was brought to the operating suite, prepped and draped in a normal sterile fashion. Multiple lymph nodes were palpated in the right axilla, however, the most inferior node was to be removed. First, the skin was anesthetized with 1% lidocaine solution. Next, using a #15 blade scalpel, an incision was made approximately 4 cm in length transversally in the inferior axilla. Next, using electro Bovie cautery, maintaining hemostasis, dissection was carried down to the lymph node. The lymph node was then completely excised using electro Bovie cautery as well as hemostats to maintain hemostasis and then lymph node was sent to specimen fresh to the lab. Several hemostats were used, suture ligated with #3-0 Vicryl suture and hemostasis was maintained. Next the deep dermal layers were approximated with #3-0 Vicryl suture. After the wound has been copiously irrigated, the skin was closed with running subcuticular #4-0 undyed Vicryl suture and the pathology is pending. The patient did tolerated the procedure well. Steri-Strips and sterile dressings were applied and the patient was transferred to the Recovery in stable condition.</span><span class="sh">"</span>
<span class="c1"># âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± (outputì€ ë¹ˆì¹¸)
</span><span class="n">prompt</span> <span class="o">=</span> <span class="n">alpaca_prompt</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">instruction</span><span class="p">,</span> <span class="n">transcription</span><span class="p">,</span> <span class="sh">""</span><span class="p">)</span>

<span class="c1"># âœ… í† í¬ë‚˜ì´ì¦ˆ + ì¶”ë¡ 
</span><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">([</span><span class="n">prompt</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># âš¡ 2ë°° ì†ë„ ì˜µì…˜ (LoRA ì ìš© ëª¨ë¸ì¸ ê²½ìš°ì—ë§Œ ì‚¬ìš© ê°€ëŠ¥)
# FastLanguageModel.for_inference(model)  # PEFT ëª¨ë¸ì—ì„œëŠ” ë³´í†µ ìƒëµ ê°€ëŠ¥
</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># âœ… ê²°ê³¼ ë””ì½”ë”©
</span><span class="nf">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">batch_decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image%207.png" alt="image.png" /></p>

<h1 id="6ï¸âƒ£-test-evaluation">6ï¸âƒ£ <strong>Test Evaluation</strong></h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Alpaca prompt í…œí”Œë¦¿
</span><span class="n">alpaca_prompt</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
{}

### Input:
{}

### Response:
{}</span><span class="sh">"""</span>

<span class="n">instruction</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Classify the following medical transcription into the correct medical specialty.</span><span class="sh">"</span>

<span class="c1"># ë¼ë²¨ ì „ì²˜ë¦¬ í•¨ìˆ˜
</span><span class="k">def</span> <span class="nf">normalize_label</span><span class="p">(</span><span class="n">label</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">label</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">/</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s"> / </span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">/</span><span class="sh">"</span><span class="p">).</span><span class="nf">strip</span><span class="p">()</span>

<span class="c1"># ì…ë ¥ ê¸¸ì´ ì œí•œìš© í† í° ìˆ˜
</span><span class="n">MAX_INPUT_TOKENS</span> <span class="o">=</span> <span class="mi">1800</span>

<span class="c1"># Test dataset ë¡œë“œ
</span><span class="n">test_dataset</span> <span class="o">=</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="sh">"</span><span class="s">hpe-ai/medical-cases-classification-tutorial</span><span class="sh">"</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">)</span>

<span class="n">labels</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="c1"># ë¼ë²¨ ì§‘í•© í™•ë³´ (ì •ê·œí™”ëœ ê¸°ì¤€ìœ¼ë¡œ)
</span><span class="n">all_classes</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="nf">list</span><span class="p">({</span><span class="nf">normalize_label</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="sh">"</span><span class="s">medical_specialty</span><span class="sh">"</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">test_dataset</span><span class="p">}))</span>

<span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="nf">tqdm</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">):</span>
    <span class="n">transcription</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="sh">"</span><span class="s">transcription</span><span class="sh">"</span><span class="p">]</span>
    <span class="n">true_label</span> <span class="o">=</span> <span class="nf">normalize_label</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="sh">"</span><span class="s">medical_specialty</span><span class="sh">"</span><span class="p">])</span>
    <span class="n">labels</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">true_label</span><span class="p">)</span>

    <span class="n">prompt</span> <span class="o">=</span> <span class="n">alpaca_prompt</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">instruction</span><span class="p">,</span> <span class="n">transcription</span><span class="p">,</span> <span class="sh">""</span><span class="p">)</span>

    <span class="c1"># í† í¬ë‚˜ì´ì§• + ê¸¸ì´ ì œí•œ
</span>    <span class="n">inputs</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="n">MAX_INPUT_TOKENS</span><span class="p">).</span><span class="nf">to</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">output_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

    <span class="c1"># "### Response:" ì´í›„ ì˜ˆì¸¡ê°’ë§Œ ì¶”ì¶œ
</span>    <span class="n">response</span> <span class="o">=</span> <span class="n">output_text</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">### Response:</span><span class="sh">"</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">strip</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="nf">normalize_label</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
    <span class="n">preds</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>

<span class="c1"># ì •í™•ë„ ë° ë¦¬í¬íŠ¸ ì¶œë ¥
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">âœ… Accuracy:</span><span class="sh">"</span><span class="p">,</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">ğŸ“„ Classification Report:</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">classification_report</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">all_classes</span><span class="p">))</span>

<span class="c1"># Confusion matrix
</span><span class="n">cm</span> <span class="o">=</span> <span class="nf">confusion_matrix</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">all_classes</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mi">14</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">all_classes</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">all_classes</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">Blues</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Confusion Matrix</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Predicted Label</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">True Label</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image%208.png" alt="image.png" /></p>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image%209.png" alt="image.png" /></p>

<h1 id="7ï¸âƒ£-saving-loading-finetuned-models">7ï¸âƒ£ <strong>Saving, loading finetuned models</strong></h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nf">save_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">lora_model</span><span class="sh">"</span><span class="p">)</span>  <span class="c1"># Local saving
</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">save_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">lora_model</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># model.push_to_hub("your_name/lora_model", token = "...") # Online saving
# tokenizer.push_to_hub("your_name/lora_model", token = "...") # Online saving
</span></code></pre></div></div>

<h1 id="8ï¸âƒ£-comparison">8ï¸âƒ£ Comparison</h1>

<h2 id="1-traintest--73">1. Train:Test = 7:3</h2>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image%2010.png" alt="image.png" /></p>

<h2 id="2-traintest--7525">2. Train:Test = 7.5:2.5</h2>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image%2011.png" alt="image.png" /></p>

<h2 id="3-traintest--82">3. Train:Test = 8:2</h2>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image%2012.png" alt="image.png" /></p>

<h2 id="4-traintest--8515">4. Train:Test = 8.5:1.5</h2>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image%2013.png" alt="image.png" /></p>

<h2 id="5-traintest--91">5. Train:Test = 9:1</h2>

<p><img src="/assets/image/2025-06-19-Llama-Fine-tuning-Test-Unsloth-Image/image%2014.png" alt="image.png" /></p>


  </div></div>

    </section>
    <footer class="condensed">
      <ul class="social about-footer condensed"><a href="https://github.com/ysm0909" target="_blank">
          <li>
            <i class="icon-github-circled"></i>
          </li>
        </a><a href="mailto:ysmm0909@naver.com" target="_blank">
          <li>
            <i class="icon-mail-alt"></i>
          </li>
        </a></ul><p class="about-footer condensed">&copy;
        2025</p><div class="about-footer condensed">
        <p>Dark Mode
          <i class="icon-moon"></i>
          <label class="switch">
            <input type="checkbox" class="dark-mode-toggle">
            <span class="slider round" onclick="toggleDarkMode()"></span>
          </label>
        </p>
      </div>
    </footer>
  </main>
  
  <script type="text/javascript" src="/assets/js/darkmode.js"></script>
  
  <script src="/assets/js/simple-jekyll-search.min.js"></script>
  <script src="/assets/js/search.js"></script>
  
</body>

</html>
